{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import vstack, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_task1_latest.csv')\n",
    "test = pd.read_csv('test_task1_latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "par_matr = vect.fit_transform(train.paragraph + train.question)\n",
    "par_matr_test = vect.fit_transform(test.paragraph + test.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(par_matr)\n",
    "y_train, y_test = train_test_split(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_test = lgb.Dataset(par_matr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.683867\n",
      "[2]\ttraining's binary_logloss: 0.675477\n",
      "[3]\ttraining's binary_logloss: 0.667881\n",
      "[4]\ttraining's binary_logloss: 0.661003\n",
      "[5]\ttraining's binary_logloss: 0.65477\n",
      "[6]\ttraining's binary_logloss: 0.64909\n",
      "[7]\ttraining's binary_logloss: 0.643942\n",
      "[8]\ttraining's binary_logloss: 0.639264\n",
      "[9]\ttraining's binary_logloss: 0.635011\n",
      "[10]\ttraining's binary_logloss: 0.631136\n",
      "[11]\ttraining's binary_logloss: 0.627577\n",
      "[12]\ttraining's binary_logloss: 0.624348\n",
      "[13]\ttraining's binary_logloss: 0.621414\n",
      "[14]\ttraining's binary_logloss: 0.618738\n",
      "[15]\ttraining's binary_logloss: 0.616311\n",
      "[16]\ttraining's binary_logloss: 0.614078\n",
      "[17]\ttraining's binary_logloss: 0.612033\n",
      "[18]\ttraining's binary_logloss: 0.610173\n",
      "[19]\ttraining's binary_logloss: 0.608482\n",
      "[20]\ttraining's binary_logloss: 0.606921\n",
      "[21]\ttraining's binary_logloss: 0.605486\n",
      "[22]\ttraining's binary_logloss: 0.604177\n",
      "[23]\ttraining's binary_logloss: 0.602987\n",
      "[24]\ttraining's binary_logloss: 0.601866\n",
      "[25]\ttraining's binary_logloss: 0.600858\n",
      "[26]\ttraining's binary_logloss: 0.599937\n",
      "[27]\ttraining's binary_logloss: 0.599098\n",
      "[28]\ttraining's binary_logloss: 0.598323\n",
      "[29]\ttraining's binary_logloss: 0.597599\n",
      "[30]\ttraining's binary_logloss: 0.596939\n",
      "[31]\ttraining's binary_logloss: 0.596301\n",
      "[32]\ttraining's binary_logloss: 0.595717\n",
      "[33]\ttraining's binary_logloss: 0.595177\n",
      "[34]\ttraining's binary_logloss: 0.594676\n",
      "[35]\ttraining's binary_logloss: 0.594216\n",
      "[36]\ttraining's binary_logloss: 0.593765\n",
      "[37]\ttraining's binary_logloss: 0.593361\n",
      "[38]\ttraining's binary_logloss: 0.592959\n",
      "[39]\ttraining's binary_logloss: 0.592595\n",
      "[40]\ttraining's binary_logloss: 0.592248\n",
      "[41]\ttraining's binary_logloss: 0.591914\n",
      "[42]\ttraining's binary_logloss: 0.59161\n",
      "[43]\ttraining's binary_logloss: 0.591318\n",
      "[44]\ttraining's binary_logloss: 0.59105\n",
      "[45]\ttraining's binary_logloss: 0.590802\n",
      "[46]\ttraining's binary_logloss: 0.590548\n",
      "[47]\ttraining's binary_logloss: 0.590317\n",
      "[48]\ttraining's binary_logloss: 0.590095\n",
      "[49]\ttraining's binary_logloss: 0.589873\n",
      "[50]\ttraining's binary_logloss: 0.589685\n",
      "[51]\ttraining's binary_logloss: 0.58947\n",
      "[52]\ttraining's binary_logloss: 0.589274\n",
      "[53]\ttraining's binary_logloss: 0.589083\n",
      "[54]\ttraining's binary_logloss: 0.588905\n",
      "[55]\ttraining's binary_logloss: 0.588738\n",
      "[56]\ttraining's binary_logloss: 0.588563\n",
      "[57]\ttraining's binary_logloss: 0.588398\n",
      "[58]\ttraining's binary_logloss: 0.58824\n",
      "[59]\ttraining's binary_logloss: 0.588075\n",
      "[60]\ttraining's binary_logloss: 0.587922\n",
      "[61]\ttraining's binary_logloss: 0.587762\n",
      "[62]\ttraining's binary_logloss: 0.587601\n",
      "[63]\ttraining's binary_logloss: 0.587459\n",
      "[64]\ttraining's binary_logloss: 0.587315\n",
      "[65]\ttraining's binary_logloss: 0.587157\n",
      "[66]\ttraining's binary_logloss: 0.587001\n",
      "[67]\ttraining's binary_logloss: 0.586858\n",
      "[68]\ttraining's binary_logloss: 0.586715\n",
      "[69]\ttraining's binary_logloss: 0.586587\n",
      "[70]\ttraining's binary_logloss: 0.586457\n",
      "[71]\ttraining's binary_logloss: 0.586313\n",
      "[72]\ttraining's binary_logloss: 0.586169\n",
      "[73]\ttraining's binary_logloss: 0.586041\n",
      "[74]\ttraining's binary_logloss: 0.585914\n",
      "[75]\ttraining's binary_logloss: 0.58578\n",
      "[76]\ttraining's binary_logloss: 0.585642\n",
      "[77]\ttraining's binary_logloss: 0.585508\n",
      "[78]\ttraining's binary_logloss: 0.585382\n",
      "[79]\ttraining's binary_logloss: 0.585259\n",
      "[80]\ttraining's binary_logloss: 0.585136\n",
      "[81]\ttraining's binary_logloss: 0.585001\n",
      "[82]\ttraining's binary_logloss: 0.584882\n",
      "[83]\ttraining's binary_logloss: 0.584743\n",
      "[84]\ttraining's binary_logloss: 0.584611\n",
      "[85]\ttraining's binary_logloss: 0.584477\n",
      "[86]\ttraining's binary_logloss: 0.584346\n",
      "[87]\ttraining's binary_logloss: 0.584227\n",
      "[88]\ttraining's binary_logloss: 0.584118\n",
      "[89]\ttraining's binary_logloss: 0.583999\n",
      "[90]\ttraining's binary_logloss: 0.583892\n",
      "[91]\ttraining's binary_logloss: 0.583761\n",
      "[92]\ttraining's binary_logloss: 0.583631\n",
      "[93]\ttraining's binary_logloss: 0.583509\n",
      "[94]\ttraining's binary_logloss: 0.583399\n",
      "[95]\ttraining's binary_logloss: 0.583281\n",
      "[96]\ttraining's binary_logloss: 0.583148\n",
      "[97]\ttraining's binary_logloss: 0.583024\n",
      "[98]\ttraining's binary_logloss: 0.582901\n",
      "[99]\ttraining's binary_logloss: 0.582786\n",
      "[100]\ttraining's binary_logloss: 0.582664\n",
      "[101]\ttraining's binary_logloss: 0.582546\n",
      "[102]\ttraining's binary_logloss: 0.582423\n",
      "[103]\ttraining's binary_logloss: 0.582285\n",
      "[104]\ttraining's binary_logloss: 0.582178\n",
      "[105]\ttraining's binary_logloss: 0.582073\n",
      "[106]\ttraining's binary_logloss: 0.581937\n",
      "[107]\ttraining's binary_logloss: 0.581813\n",
      "[108]\ttraining's binary_logloss: 0.581693\n",
      "[109]\ttraining's binary_logloss: 0.581577\n",
      "[110]\ttraining's binary_logloss: 0.581464\n",
      "[111]\ttraining's binary_logloss: 0.581327\n",
      "[112]\ttraining's binary_logloss: 0.581213\n",
      "[113]\ttraining's binary_logloss: 0.58111\n",
      "[114]\ttraining's binary_logloss: 0.580992\n",
      "[115]\ttraining's binary_logloss: 0.580872\n",
      "[116]\ttraining's binary_logloss: 0.580758\n",
      "[117]\ttraining's binary_logloss: 0.580652\n",
      "[118]\ttraining's binary_logloss: 0.580542\n",
      "[119]\ttraining's binary_logloss: 0.580425\n",
      "[120]\ttraining's binary_logloss: 0.580321\n",
      "[121]\ttraining's binary_logloss: 0.580209\n",
      "[122]\ttraining's binary_logloss: 0.580099\n",
      "[123]\ttraining's binary_logloss: 0.579994\n",
      "[124]\ttraining's binary_logloss: 0.579894\n",
      "[125]\ttraining's binary_logloss: 0.579794\n",
      "[126]\ttraining's binary_logloss: 0.579677\n",
      "[127]\ttraining's binary_logloss: 0.579569\n",
      "[128]\ttraining's binary_logloss: 0.579462\n",
      "[129]\ttraining's binary_logloss: 0.579352\n",
      "[130]\ttraining's binary_logloss: 0.579255\n",
      "[131]\ttraining's binary_logloss: 0.579141\n",
      "[132]\ttraining's binary_logloss: 0.579034\n",
      "[133]\ttraining's binary_logloss: 0.578931\n",
      "[134]\ttraining's binary_logloss: 0.578817\n",
      "[135]\ttraining's binary_logloss: 0.578717\n",
      "[136]\ttraining's binary_logloss: 0.578607\n",
      "[137]\ttraining's binary_logloss: 0.578509\n",
      "[138]\ttraining's binary_logloss: 0.578381\n",
      "[139]\ttraining's binary_logloss: 0.578268\n",
      "[140]\ttraining's binary_logloss: 0.57815\n",
      "[141]\ttraining's binary_logloss: 0.578039\n",
      "[142]\ttraining's binary_logloss: 0.577905\n",
      "[143]\ttraining's binary_logloss: 0.577778\n",
      "[144]\ttraining's binary_logloss: 0.577674\n",
      "[145]\ttraining's binary_logloss: 0.577567\n",
      "[146]\ttraining's binary_logloss: 0.577461\n",
      "[147]\ttraining's binary_logloss: 0.577359\n",
      "[148]\ttraining's binary_logloss: 0.577255\n",
      "[149]\ttraining's binary_logloss: 0.577163\n",
      "[150]\ttraining's binary_logloss: 0.577057\n",
      "[151]\ttraining's binary_logloss: 0.576935\n",
      "[152]\ttraining's binary_logloss: 0.57683\n",
      "[153]\ttraining's binary_logloss: 0.576719\n",
      "[154]\ttraining's binary_logloss: 0.576614\n",
      "[155]\ttraining's binary_logloss: 0.576501\n",
      "[156]\ttraining's binary_logloss: 0.576382\n",
      "[157]\ttraining's binary_logloss: 0.576281\n",
      "[158]\ttraining's binary_logloss: 0.576183\n",
      "[159]\ttraining's binary_logloss: 0.576087\n",
      "[160]\ttraining's binary_logloss: 0.57599\n",
      "[161]\ttraining's binary_logloss: 0.575877\n",
      "[162]\ttraining's binary_logloss: 0.575776\n",
      "[163]\ttraining's binary_logloss: 0.575682\n",
      "[164]\ttraining's binary_logloss: 0.575579\n",
      "[165]\ttraining's binary_logloss: 0.575486\n",
      "[166]\ttraining's binary_logloss: 0.575378\n",
      "[167]\ttraining's binary_logloss: 0.575252\n",
      "[168]\ttraining's binary_logloss: 0.575138\n",
      "[169]\ttraining's binary_logloss: 0.575015\n",
      "[170]\ttraining's binary_logloss: 0.574912\n",
      "[171]\ttraining's binary_logloss: 0.574811\n",
      "[172]\ttraining's binary_logloss: 0.57471\n",
      "[173]\ttraining's binary_logloss: 0.574616\n",
      "[174]\ttraining's binary_logloss: 0.574528\n",
      "[175]\ttraining's binary_logloss: 0.574437\n",
      "[176]\ttraining's binary_logloss: 0.574331\n",
      "[177]\ttraining's binary_logloss: 0.574233\n",
      "[178]\ttraining's binary_logloss: 0.574132\n",
      "[179]\ttraining's binary_logloss: 0.574037\n",
      "[180]\ttraining's binary_logloss: 0.573918\n",
      "[181]\ttraining's binary_logloss: 0.573814\n",
      "[182]\ttraining's binary_logloss: 0.573711\n",
      "[183]\ttraining's binary_logloss: 0.57362\n",
      "[184]\ttraining's binary_logloss: 0.573506\n",
      "[185]\ttraining's binary_logloss: 0.573415\n",
      "[186]\ttraining's binary_logloss: 0.573316\n",
      "[187]\ttraining's binary_logloss: 0.573215\n",
      "[188]\ttraining's binary_logloss: 0.573113\n",
      "[189]\ttraining's binary_logloss: 0.573031\n",
      "[190]\ttraining's binary_logloss: 0.572921\n",
      "[191]\ttraining's binary_logloss: 0.572792\n",
      "[192]\ttraining's binary_logloss: 0.572662\n",
      "[193]\ttraining's binary_logloss: 0.572564\n",
      "[194]\ttraining's binary_logloss: 0.572449\n",
      "[195]\ttraining's binary_logloss: 0.572355\n",
      "[196]\ttraining's binary_logloss: 0.572256\n",
      "[197]\ttraining's binary_logloss: 0.572153\n",
      "[198]\ttraining's binary_logloss: 0.572033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199]\ttraining's binary_logloss: 0.571939\n",
      "[200]\ttraining's binary_logloss: 0.571849\n",
      "[201]\ttraining's binary_logloss: 0.571749\n",
      "[202]\ttraining's binary_logloss: 0.571658\n",
      "[203]\ttraining's binary_logloss: 0.57156\n",
      "[204]\ttraining's binary_logloss: 0.571474\n",
      "[205]\ttraining's binary_logloss: 0.571391\n",
      "[206]\ttraining's binary_logloss: 0.57129\n",
      "[207]\ttraining's binary_logloss: 0.571179\n",
      "[208]\ttraining's binary_logloss: 0.571093\n",
      "[209]\ttraining's binary_logloss: 0.571012\n",
      "[210]\ttraining's binary_logloss: 0.570915\n",
      "[211]\ttraining's binary_logloss: 0.570821\n",
      "[212]\ttraining's binary_logloss: 0.570733\n",
      "[213]\ttraining's binary_logloss: 0.570641\n",
      "[214]\ttraining's binary_logloss: 0.570542\n",
      "[215]\ttraining's binary_logloss: 0.570456\n",
      "[216]\ttraining's binary_logloss: 0.570366\n",
      "[217]\ttraining's binary_logloss: 0.570274\n",
      "[218]\ttraining's binary_logloss: 0.570187\n",
      "[219]\ttraining's binary_logloss: 0.57009\n",
      "[220]\ttraining's binary_logloss: 0.570006\n",
      "[221]\ttraining's binary_logloss: 0.569903\n",
      "[222]\ttraining's binary_logloss: 0.569816\n",
      "[223]\ttraining's binary_logloss: 0.569726\n",
      "[224]\ttraining's binary_logloss: 0.569638\n",
      "[225]\ttraining's binary_logloss: 0.569546\n",
      "[226]\ttraining's binary_logloss: 0.569452\n",
      "[227]\ttraining's binary_logloss: 0.56936\n",
      "[228]\ttraining's binary_logloss: 0.569269\n",
      "[229]\ttraining's binary_logloss: 0.569183\n",
      "[230]\ttraining's binary_logloss: 0.5691\n",
      "[231]\ttraining's binary_logloss: 0.569006\n",
      "[232]\ttraining's binary_logloss: 0.568915\n",
      "[233]\ttraining's binary_logloss: 0.568832\n",
      "[234]\ttraining's binary_logloss: 0.568753\n",
      "[235]\ttraining's binary_logloss: 0.56866\n",
      "[236]\ttraining's binary_logloss: 0.568562\n",
      "[237]\ttraining's binary_logloss: 0.568474\n",
      "[238]\ttraining's binary_logloss: 0.568383\n",
      "[239]\ttraining's binary_logloss: 0.5683\n",
      "[240]\ttraining's binary_logloss: 0.568212\n",
      "[241]\ttraining's binary_logloss: 0.568109\n",
      "[242]\ttraining's binary_logloss: 0.56801\n",
      "[243]\ttraining's binary_logloss: 0.567912\n",
      "[244]\ttraining's binary_logloss: 0.567824\n",
      "[245]\ttraining's binary_logloss: 0.567739\n",
      "[246]\ttraining's binary_logloss: 0.567642\n",
      "[247]\ttraining's binary_logloss: 0.567548\n",
      "[248]\ttraining's binary_logloss: 0.567464\n",
      "[249]\ttraining's binary_logloss: 0.567376\n",
      "[250]\ttraining's binary_logloss: 0.567293\n",
      "[251]\ttraining's binary_logloss: 0.567199\n",
      "[252]\ttraining's binary_logloss: 0.567107\n",
      "[253]\ttraining's binary_logloss: 0.567026\n",
      "[254]\ttraining's binary_logloss: 0.566947\n",
      "[255]\ttraining's binary_logloss: 0.566872\n",
      "[256]\ttraining's binary_logloss: 0.566781\n",
      "[257]\ttraining's binary_logloss: 0.566695\n",
      "[258]\ttraining's binary_logloss: 0.56661\n",
      "[259]\ttraining's binary_logloss: 0.566531\n",
      "[260]\ttraining's binary_logloss: 0.566451\n",
      "[261]\ttraining's binary_logloss: 0.566361\n",
      "[262]\ttraining's binary_logloss: 0.56628\n",
      "[263]\ttraining's binary_logloss: 0.566199\n",
      "[264]\ttraining's binary_logloss: 0.566122\n",
      "[265]\ttraining's binary_logloss: 0.566034\n",
      "[266]\ttraining's binary_logloss: 0.565947\n",
      "[267]\ttraining's binary_logloss: 0.565861\n",
      "[268]\ttraining's binary_logloss: 0.565777\n",
      "[269]\ttraining's binary_logloss: 0.565697\n",
      "[270]\ttraining's binary_logloss: 0.565607\n",
      "[271]\ttraining's binary_logloss: 0.565516\n",
      "[272]\ttraining's binary_logloss: 0.56542\n",
      "[273]\ttraining's binary_logloss: 0.565324\n",
      "[274]\ttraining's binary_logloss: 0.565242\n",
      "[275]\ttraining's binary_logloss: 0.565157\n",
      "[276]\ttraining's binary_logloss: 0.565061\n",
      "[277]\ttraining's binary_logloss: 0.56498\n",
      "[278]\ttraining's binary_logloss: 0.564863\n",
      "[279]\ttraining's binary_logloss: 0.564759\n",
      "[280]\ttraining's binary_logloss: 0.56467\n",
      "[281]\ttraining's binary_logloss: 0.56458\n",
      "[282]\ttraining's binary_logloss: 0.564499\n",
      "[283]\ttraining's binary_logloss: 0.564419\n",
      "[284]\ttraining's binary_logloss: 0.56434\n",
      "[285]\ttraining's binary_logloss: 0.564271\n",
      "[286]\ttraining's binary_logloss: 0.564164\n",
      "[287]\ttraining's binary_logloss: 0.56407\n",
      "[288]\ttraining's binary_logloss: 0.563988\n",
      "[289]\ttraining's binary_logloss: 0.563899\n",
      "[290]\ttraining's binary_logloss: 0.563812\n",
      "[291]\ttraining's binary_logloss: 0.563726\n",
      "[292]\ttraining's binary_logloss: 0.563645\n",
      "[293]\ttraining's binary_logloss: 0.563564\n",
      "[294]\ttraining's binary_logloss: 0.563487\n",
      "[295]\ttraining's binary_logloss: 0.563397\n",
      "[296]\ttraining's binary_logloss: 0.563307\n",
      "[297]\ttraining's binary_logloss: 0.563218\n",
      "[298]\ttraining's binary_logloss: 0.563141\n",
      "[299]\ttraining's binary_logloss: 0.563057\n",
      "[300]\ttraining's binary_logloss: 0.562973\n",
      "[301]\ttraining's binary_logloss: 0.562887\n",
      "[302]\ttraining's binary_logloss: 0.562793\n",
      "[303]\ttraining's binary_logloss: 0.562718\n",
      "[304]\ttraining's binary_logloss: 0.562647\n",
      "[305]\ttraining's binary_logloss: 0.562576\n",
      "[306]\ttraining's binary_logloss: 0.562489\n",
      "[307]\ttraining's binary_logloss: 0.562416\n",
      "[308]\ttraining's binary_logloss: 0.562339\n",
      "[309]\ttraining's binary_logloss: 0.562267\n",
      "[310]\ttraining's binary_logloss: 0.562179\n",
      "[311]\ttraining's binary_logloss: 0.562093\n",
      "[312]\ttraining's binary_logloss: 0.561996\n",
      "[313]\ttraining's binary_logloss: 0.561922\n",
      "[314]\ttraining's binary_logloss: 0.561838\n",
      "[315]\ttraining's binary_logloss: 0.56175\n",
      "[316]\ttraining's binary_logloss: 0.561668\n",
      "[317]\ttraining's binary_logloss: 0.561587\n",
      "[318]\ttraining's binary_logloss: 0.561504\n",
      "[319]\ttraining's binary_logloss: 0.561428\n",
      "[320]\ttraining's binary_logloss: 0.561342\n",
      "[321]\ttraining's binary_logloss: 0.56126\n",
      "[322]\ttraining's binary_logloss: 0.561186\n",
      "[323]\ttraining's binary_logloss: 0.561103\n",
      "[324]\ttraining's binary_logloss: 0.561027\n",
      "[325]\ttraining's binary_logloss: 0.560955\n",
      "[326]\ttraining's binary_logloss: 0.560869\n",
      "[327]\ttraining's binary_logloss: 0.560783\n",
      "[328]\ttraining's binary_logloss: 0.560703\n",
      "[329]\ttraining's binary_logloss: 0.560624\n",
      "[330]\ttraining's binary_logloss: 0.560554\n",
      "[331]\ttraining's binary_logloss: 0.560472\n",
      "[332]\ttraining's binary_logloss: 0.560391\n",
      "[333]\ttraining's binary_logloss: 0.560315\n",
      "[334]\ttraining's binary_logloss: 0.56023\n",
      "[335]\ttraining's binary_logloss: 0.560164\n",
      "[336]\ttraining's binary_logloss: 0.560083\n",
      "[337]\ttraining's binary_logloss: 0.560009\n",
      "[338]\ttraining's binary_logloss: 0.559931\n",
      "[339]\ttraining's binary_logloss: 0.559862\n",
      "[340]\ttraining's binary_logloss: 0.55979\n",
      "[341]\ttraining's binary_logloss: 0.559703\n",
      "[342]\ttraining's binary_logloss: 0.55962\n",
      "[343]\ttraining's binary_logloss: 0.55955\n",
      "[344]\ttraining's binary_logloss: 0.559474\n",
      "[345]\ttraining's binary_logloss: 0.559405\n",
      "[346]\ttraining's binary_logloss: 0.559321\n",
      "[347]\ttraining's binary_logloss: 0.559227\n",
      "[348]\ttraining's binary_logloss: 0.559156\n",
      "[349]\ttraining's binary_logloss: 0.559078\n",
      "[350]\ttraining's binary_logloss: 0.559002\n",
      "[351]\ttraining's binary_logloss: 0.558913\n",
      "[352]\ttraining's binary_logloss: 0.558848\n",
      "[353]\ttraining's binary_logloss: 0.558782\n",
      "[354]\ttraining's binary_logloss: 0.558694\n",
      "[355]\ttraining's binary_logloss: 0.558626\n",
      "[356]\ttraining's binary_logloss: 0.558549\n",
      "[357]\ttraining's binary_logloss: 0.558472\n",
      "[358]\ttraining's binary_logloss: 0.558399\n",
      "[359]\ttraining's binary_logloss: 0.558317\n",
      "[360]\ttraining's binary_logloss: 0.55825\n",
      "[361]\ttraining's binary_logloss: 0.558172\n",
      "[362]\ttraining's binary_logloss: 0.558096\n",
      "[363]\ttraining's binary_logloss: 0.558024\n",
      "[364]\ttraining's binary_logloss: 0.557948\n",
      "[365]\ttraining's binary_logloss: 0.557869\n",
      "[366]\ttraining's binary_logloss: 0.557771\n",
      "[367]\ttraining's binary_logloss: 0.557693\n",
      "[368]\ttraining's binary_logloss: 0.55762\n",
      "[369]\ttraining's binary_logloss: 0.55754\n",
      "[370]\ttraining's binary_logloss: 0.55746\n",
      "[371]\ttraining's binary_logloss: 0.557376\n",
      "[372]\ttraining's binary_logloss: 0.557296\n",
      "[373]\ttraining's binary_logloss: 0.557222\n",
      "[374]\ttraining's binary_logloss: 0.557148\n",
      "[375]\ttraining's binary_logloss: 0.557069\n",
      "[376]\ttraining's binary_logloss: 0.556982\n",
      "[377]\ttraining's binary_logloss: 0.55691\n",
      "[378]\ttraining's binary_logloss: 0.55684\n",
      "[379]\ttraining's binary_logloss: 0.556763\n",
      "[380]\ttraining's binary_logloss: 0.556682\n",
      "[381]\ttraining's binary_logloss: 0.556605\n",
      "[382]\ttraining's binary_logloss: 0.556532\n",
      "[383]\ttraining's binary_logloss: 0.556469\n",
      "[384]\ttraining's binary_logloss: 0.556389\n",
      "[385]\ttraining's binary_logloss: 0.556327\n",
      "[386]\ttraining's binary_logloss: 0.55626\n",
      "[387]\ttraining's binary_logloss: 0.556195\n",
      "[388]\ttraining's binary_logloss: 0.556124\n",
      "[389]\ttraining's binary_logloss: 0.556055\n",
      "[390]\ttraining's binary_logloss: 0.555991\n",
      "[391]\ttraining's binary_logloss: 0.555899\n",
      "[392]\ttraining's binary_logloss: 0.55582\n",
      "[393]\ttraining's binary_logloss: 0.555732\n",
      "[394]\ttraining's binary_logloss: 0.555655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[395]\ttraining's binary_logloss: 0.555582\n",
      "[396]\ttraining's binary_logloss: 0.555508\n",
      "[397]\ttraining's binary_logloss: 0.55544\n",
      "[398]\ttraining's binary_logloss: 0.555368\n",
      "[399]\ttraining's binary_logloss: 0.555296\n",
      "[400]\ttraining's binary_logloss: 0.555231\n",
      "[401]\ttraining's binary_logloss: 0.555147\n",
      "[402]\ttraining's binary_logloss: 0.555079\n",
      "[403]\ttraining's binary_logloss: 0.555006\n",
      "[404]\ttraining's binary_logloss: 0.554937\n",
      "[405]\ttraining's binary_logloss: 0.554845\n",
      "[406]\ttraining's binary_logloss: 0.554769\n",
      "[407]\ttraining's binary_logloss: 0.554698\n",
      "[408]\ttraining's binary_logloss: 0.554633\n",
      "[409]\ttraining's binary_logloss: 0.554566\n",
      "[410]\ttraining's binary_logloss: 0.554502\n",
      "[411]\ttraining's binary_logloss: 0.554411\n",
      "[412]\ttraining's binary_logloss: 0.554332\n",
      "[413]\ttraining's binary_logloss: 0.554243\n",
      "[414]\ttraining's binary_logloss: 0.554173\n",
      "[415]\ttraining's binary_logloss: 0.554099\n",
      "[416]\ttraining's binary_logloss: 0.554025\n",
      "[417]\ttraining's binary_logloss: 0.553958\n",
      "[418]\ttraining's binary_logloss: 0.553893\n",
      "[419]\ttraining's binary_logloss: 0.553821\n",
      "[420]\ttraining's binary_logloss: 0.553756\n",
      "[421]\ttraining's binary_logloss: 0.55368\n",
      "[422]\ttraining's binary_logloss: 0.553615\n",
      "[423]\ttraining's binary_logloss: 0.55355\n",
      "[424]\ttraining's binary_logloss: 0.55348\n",
      "[425]\ttraining's binary_logloss: 0.553413\n",
      "[426]\ttraining's binary_logloss: 0.553345\n",
      "[427]\ttraining's binary_logloss: 0.553276\n",
      "[428]\ttraining's binary_logloss: 0.553206\n",
      "[429]\ttraining's binary_logloss: 0.55314\n",
      "[430]\ttraining's binary_logloss: 0.553075\n",
      "[431]\ttraining's binary_logloss: 0.552999\n",
      "[432]\ttraining's binary_logloss: 0.552934\n",
      "[433]\ttraining's binary_logloss: 0.552876\n",
      "[434]\ttraining's binary_logloss: 0.552786\n",
      "[435]\ttraining's binary_logloss: 0.552717\n",
      "[436]\ttraining's binary_logloss: 0.552635\n",
      "[437]\ttraining's binary_logloss: 0.552562\n",
      "[438]\ttraining's binary_logloss: 0.552455\n",
      "[439]\ttraining's binary_logloss: 0.552394\n",
      "[440]\ttraining's binary_logloss: 0.552318\n",
      "[441]\ttraining's binary_logloss: 0.552239\n",
      "[442]\ttraining's binary_logloss: 0.552175\n",
      "[443]\ttraining's binary_logloss: 0.552113\n",
      "[444]\ttraining's binary_logloss: 0.552026\n",
      "[445]\ttraining's binary_logloss: 0.55197\n",
      "[446]\ttraining's binary_logloss: 0.551891\n",
      "[447]\ttraining's binary_logloss: 0.551823\n",
      "[448]\ttraining's binary_logloss: 0.551756\n",
      "[449]\ttraining's binary_logloss: 0.551686\n",
      "[450]\ttraining's binary_logloss: 0.551625\n",
      "[451]\ttraining's binary_logloss: 0.551549\n",
      "[452]\ttraining's binary_logloss: 0.551482\n",
      "[453]\ttraining's binary_logloss: 0.551416\n",
      "[454]\ttraining's binary_logloss: 0.551358\n",
      "[455]\ttraining's binary_logloss: 0.551302\n",
      "[456]\ttraining's binary_logloss: 0.551215\n",
      "[457]\ttraining's binary_logloss: 0.551141\n",
      "[458]\ttraining's binary_logloss: 0.551068\n",
      "[459]\ttraining's binary_logloss: 0.551\n",
      "[460]\ttraining's binary_logloss: 0.550931\n",
      "[461]\ttraining's binary_logloss: 0.55086\n",
      "[462]\ttraining's binary_logloss: 0.550804\n",
      "[463]\ttraining's binary_logloss: 0.550746\n",
      "[464]\ttraining's binary_logloss: 0.550694\n",
      "[465]\ttraining's binary_logloss: 0.550632\n",
      "[466]\ttraining's binary_logloss: 0.550552\n",
      "[467]\ttraining's binary_logloss: 0.550483\n",
      "[468]\ttraining's binary_logloss: 0.55041\n",
      "[469]\ttraining's binary_logloss: 0.550343\n",
      "[470]\ttraining's binary_logloss: 0.550273\n",
      "[471]\ttraining's binary_logloss: 0.550169\n",
      "[472]\ttraining's binary_logloss: 0.550085\n",
      "[473]\ttraining's binary_logloss: 0.550022\n",
      "[474]\ttraining's binary_logloss: 0.549963\n",
      "[475]\ttraining's binary_logloss: 0.549865\n",
      "[476]\ttraining's binary_logloss: 0.54978\n",
      "[477]\ttraining's binary_logloss: 0.549711\n",
      "[478]\ttraining's binary_logloss: 0.54965\n",
      "[479]\ttraining's binary_logloss: 0.549586\n",
      "[480]\ttraining's binary_logloss: 0.549517\n",
      "[481]\ttraining's binary_logloss: 0.54945\n",
      "[482]\ttraining's binary_logloss: 0.549389\n",
      "[483]\ttraining's binary_logloss: 0.549326\n",
      "[484]\ttraining's binary_logloss: 0.549271\n",
      "[485]\ttraining's binary_logloss: 0.549211\n",
      "[486]\ttraining's binary_logloss: 0.549131\n",
      "[487]\ttraining's binary_logloss: 0.549067\n",
      "[488]\ttraining's binary_logloss: 0.549005\n",
      "[489]\ttraining's binary_logloss: 0.548919\n",
      "[490]\ttraining's binary_logloss: 0.548855\n",
      "[491]\ttraining's binary_logloss: 0.548783\n",
      "[492]\ttraining's binary_logloss: 0.548708\n",
      "[493]\ttraining's binary_logloss: 0.548649\n",
      "[494]\ttraining's binary_logloss: 0.548584\n",
      "[495]\ttraining's binary_logloss: 0.548528\n",
      "[496]\ttraining's binary_logloss: 0.548457\n",
      "[497]\ttraining's binary_logloss: 0.548389\n",
      "[498]\ttraining's binary_logloss: 0.548317\n",
      "[499]\ttraining's binary_logloss: 0.548251\n",
      "[500]\ttraining's binary_logloss: 0.54819\n"
     ]
    }
   ],
   "source": [
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=500,\n",
    "                valid_sets=lgb_train)  # eval training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gbm.predict(par_matr_test)\n",
    "pred[pred < 0] = 0\n",
    "pred[pred >= 0.25] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74277"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred[pred==0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
